{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e2c728",
   "metadata": {},
   "source": [
    "# Abordagem 5\n",
    "\n",
    "Usando a abordagem 5 para gerar templates com foco em templates positivos e negativos. Uma possível aplicação seria testar a capacidade linguística \"Vocabulary\" com o teste MFT.\n",
    "\n",
    "As etapas desta abordagem são:\n",
    "\n",
    "1. Quebrar as instâncias em sentenças\n",
    "2. Rankear as palavras de cada sentença\n",
    "3. Filtrar as sentenças pelo tamanho (maior ou igual a 5 palavras)\n",
    "4. Filtrar sentenças com palavras relevantes (verbos ou adjetivos)\n",
    "5. Filtrar sentenças com alta confiança na predição das palavras relevantes da etapa anterior\n",
    "6. Substituir as palavras relevantes por máscaras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897c3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da847fc",
   "metadata": {},
   "source": [
    "## Carregando o dataset, o modelo alvo e os modelos auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e018fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Here's example number 87,358 of Hollywood's anti-Biblical bias, so typical of them.&lt;br /&gt;&lt;br /&gt;Early on, Ray Liotta's wife has did and women are being interviewed for the position of housekeeper. The first interviewee is an old-fashioned-looking (dress, mannerisms, speech) who immediately lays down here strict rules, stating that \"there will be two hours of Bible study ever day.\"&lt;br /&gt;&lt;br /&gt;This is said, of course, to make it sound like reading the Bible is the worse punishment you could ever inflict on someone, especially a kid. Once again, the Bible is equated with stuffy, mean-spirited people. That woman, of course, is dismissed immediately.&lt;br /&gt;&lt;br /&gt;Naturally, the liberal black woman (Whoopi Goldberg - who else?) is the one who is hired and, voilà, saves the day! &lt;br /&gt;&lt;br /&gt;Yawn.</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't know about the real Cobb but I got the distinct impression that the filmmakers' aim was to try to soften his jagged edges and reputation, not give us a true portrait of the man himself. In the movie, besides a few racist remarks, he's shown to be just another hard-nosed, cantakerous old coot (he's so full of life!) with a heart of gold(more or less). This is also the worst acting I've seen T.L.Jones do(he brings nothing new or subtle to his stereotyped character). He just doesn't flesh out Cobb in a way that pulls me into the movie. Not for one minute did I forget that it was Tommy Lee Jones on the screen pretending to be Ty Cobb. Robert Wuhl didnt impress either. The \"comedic\" elements in this movie were just distracting and didnt ring true at all. A bloody waste of time, it is</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Reba is a very dumb show. You can predict pretty much anything that's about to happen. Barbra Jean is just too stupid. It's like she's not even a character. A show like this should at least have SOMEONE who resembles a real-life person. I guess Barbra Jean represents a retarded person. Keira or whatever her name is, Reba, Brock, they're all stupid! Keira is like the smartest person on the show, and she's still stupid. EVERYONE IS STUPID! That's my opinion on Reba. Since I have said all I can say about this show, I'll just take up the next few lines of text by saying what I am currently saying right now and do it until there's 10 lines. There. Reba gets 2/10.</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>\"One Crazy Summer\" is the funniest, craziest (not necessarily the best), movie I have ever seen.&lt;br /&gt;&lt;br /&gt;Just when one crazy scene is done, another emerges. It never lets you rest. Just one thing after another. The soundtrack is great. The songs are the right ones for the scenes.&lt;br /&gt;&lt;br /&gt;It is also a clean movie. Little that is dirty in it.&lt;br /&gt;&lt;br /&gt;Of course, it has the story of the guys you wouldn't trust with your lunch money, taking up a challenge, and winning over people with more resources. Who'd want to see it if they failed? There is a serious side, in that parents and children do not live up to each others' dreams. One should always have an open mind, and weigh all the options. This applies both to parents and children. In \"One Crazy Summer\", the parents are wrong. This is not always the case.</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>\"A young man, recently engaged to be married, is the victim of a traffic accident and dies as a result of his injuries. His father, desperate to revive his son, agrees to let a scientist friend try his experimental soul transmigration process to save him. After the young man returns to life, the father and fiancée notice a dark and violent change in the young man's behavior, leading them to believe something went horribly wrong in the revival process,\" according to the DVD sleeve's synopsis.&lt;br /&gt;&lt;br /&gt;At one point, Edward Norris (as Philip Bennett) is asked, \"What do you think this is, Boys Town?\" Mr. Norris should know, since he was in \"Boys Town\". \"The Man with Two Lives \" is more like \"Black Friday\" minus Karloff and Lugosi. You do the math. This film might have been a contender, with a re-worked script; it does feature an intriguing final act. After a tepid \"shoot out\", hang in for the drama to pick up with a well-played scene between star Norris and pursuing detective Addison Richards (as George Bradley).&lt;br /&gt;&lt;br /&gt;**** The Man with Two Lives (1942) Phil Rosen ~ Edward Norris, Eleanor Lawson, Addison Richards</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2      0   \n",
       "3      1   \n",
       "4      0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                  Here's example number 87,358 of Hollywood's anti-Biblical bias, so typical of them.<br /><br />Early on, Ray Liotta's wife has did and women are being interviewed for the position of housekeeper. The first interviewee is an old-fashioned-looking (dress, mannerisms, speech) who immediately lays down here strict rules, stating that \"there will be two hours of Bible study ever day.\"<br /><br />This is said, of course, to make it sound like reading the Bible is the worse punishment you could ever inflict on someone, especially a kid. Once again, the Bible is equated with stuffy, mean-spirited people. That woman, of course, is dismissed immediately.<br /><br />Naturally, the liberal black woman (Whoopi Goldberg - who else?) is the one who is hired and, voilà, saves the day! <br /><br />Yawn.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                  I don't know about the real Cobb but I got the distinct impression that the filmmakers' aim was to try to soften his jagged edges and reputation, not give us a true portrait of the man himself. In the movie, besides a few racist remarks, he's shown to be just another hard-nosed, cantakerous old coot (he's so full of life!) with a heart of gold(more or less). This is also the worst acting I've seen T.L.Jones do(he brings nothing new or subtle to his stereotyped character). He just doesn't flesh out Cobb in a way that pulls me into the movie. Not for one minute did I forget that it was Tommy Lee Jones on the screen pretending to be Ty Cobb. Robert Wuhl didnt impress either. The \"comedic\" elements in this movie were just distracting and didnt ring true at all. A bloody waste of time, it is   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Reba is a very dumb show. You can predict pretty much anything that's about to happen. Barbra Jean is just too stupid. It's like she's not even a character. A show like this should at least have SOMEONE who resembles a real-life person. I guess Barbra Jean represents a retarded person. Keira or whatever her name is, Reba, Brock, they're all stupid! Keira is like the smartest person on the show, and she's still stupid. EVERYONE IS STUPID! That's my opinion on Reba. Since I have said all I can say about this show, I'll just take up the next few lines of text by saying what I am currently saying right now and do it until there's 10 lines. There. Reba gets 2/10.   \n",
       "3                                                                                                                                                                                                                                                                                                                          \"One Crazy Summer\" is the funniest, craziest (not necessarily the best), movie I have ever seen.<br /><br />Just when one crazy scene is done, another emerges. It never lets you rest. Just one thing after another. The soundtrack is great. The songs are the right ones for the scenes.<br /><br />It is also a clean movie. Little that is dirty in it.<br /><br />Of course, it has the story of the guys you wouldn't trust with your lunch money, taking up a challenge, and winning over people with more resources. Who'd want to see it if they failed? There is a serious side, in that parents and children do not live up to each others' dreams. One should always have an open mind, and weigh all the options. This applies both to parents and children. In \"One Crazy Summer\", the parents are wrong. This is not always the case.   \n",
       "4  \"A young man, recently engaged to be married, is the victim of a traffic accident and dies as a result of his injuries. His father, desperate to revive his son, agrees to let a scientist friend try his experimental soul transmigration process to save him. After the young man returns to life, the father and fiancée notice a dark and violent change in the young man's behavior, leading them to believe something went horribly wrong in the revival process,\" according to the DVD sleeve's synopsis.<br /><br />At one point, Edward Norris (as Philip Bennett) is asked, \"What do you think this is, Boys Town?\" Mr. Norris should know, since he was in \"Boys Town\". \"The Man with Two Lives \" is more like \"Black Friday\" minus Karloff and Lugosi. You do the math. This film might have been a contender, with a re-worked script; it does feature an intriguing final act. After a tepid \"shoot out\", hang in for the drama to pick up with a well-played scene between star Norris and pursuing detective Addison Richards (as George Bradley).<br /><br />**** The Man with Two Lives (1942) Phil Rosen ~ Edward Norris, Eleanor Lawson, Addison Richards   \n",
       "\n",
       "   words  \n",
       "0    127  \n",
       "1    149  \n",
       "2    124  \n",
       "3    149  \n",
       "4    196  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "imdb_df = pd.read_csv('../data/imdb_sampled/data-1000samples.csv')\n",
    "imdb_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264d0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "def pre_proccess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[\"\\',!-.:-@0-9/]()', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Wrapper to adapt output format\n",
    "class SentimentAnalisysModelWrapper:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __predict(self, text_input):\n",
    "        text_preprocessed = pre_proccess(text_input)\n",
    "        tokenized = self.tokenizer(text_preprocessed, padding=True, truncation=True, max_length=512, \n",
    "                                    add_special_tokens = True, return_tensors=\"pt\")\n",
    "        \n",
    "        tensor_logits = self.model(**tokenized)\n",
    "        prob = softmax(tensor_logits[0]).detach().numpy()\n",
    "        pred = np.argmax(prob)\n",
    "        \n",
    "        return pred, prob\n",
    "    \n",
    "    def predict_label(self, text_inputs):\n",
    "        return self.predict(text_inputs)[0]\n",
    "        \n",
    "    def predict_proba(self, text_inputs):\n",
    "        return self.predict(text_inputs)[1]\n",
    "        \n",
    "    def predict(self, text_inputs):\n",
    "        if isinstance(text_inputs, str):\n",
    "            text_inputs = [text_inputs]\n",
    "        \n",
    "        preds = []\n",
    "        probs = []\n",
    "\n",
    "        for text_input in text_inputs:\n",
    "            pred, prob = self.__predict(text_input)\n",
    "            preds.append(pred)\n",
    "            probs.append(prob[0])\n",
    "\n",
    "        return np.array(preds), np.array(probs) # ([0, 1], [[0.99, 0.01], [0.03, 0.97]])\n",
    "\n",
    "# Auxiliar function to load and wrap a model from Hugging Face\n",
    "def load_model(model_name):\n",
    "    print(f'Loading model {model_name}...')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    return SentimentAnalisysModelWrapper(model, tokenizer)\n",
    "\n",
    "# Hugging Face hosted model names \n",
    "imdb_models = {\n",
    "    'bert': 'textattack/bert-base-uncased-imdb', \n",
    "    'albert': 'textattack/albert-base-v2-imdb', \n",
    "    'distilbert': 'textattack/distilbert-base-uncased-imdb', \n",
    "    'roberta': 'textattack/roberta-base-imdb', \n",
    "    'xlnet': 'textattack/xlnet-base-cased-imdb'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f271eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model textattack/albert-base-v2-imdb...\n",
      "Loading model textattack/distilbert-base-uncased-imdb...\n",
      "Loading model textattack/roberta-base-imdb...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-imdb were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model textattack/xlnet-base-cased-imdb...\n",
      "Loading model textattack/bert-base-uncased-imdb...\n"
     ]
    }
   ],
   "source": [
    "m1 = load_model(imdb_models['albert'])\n",
    "m2 = load_model(imdb_models['distilbert'])\n",
    "m3 = load_model(imdb_models['roberta'])\n",
    "m4 = load_model(imdb_models['xlnet'])\n",
    "\n",
    "# Models to be used as oracle\n",
    "models = [m1, m2, m3, m4]\n",
    "# Target model\n",
    "model = load_model(imdb_models['bert'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae89b5",
   "metadata": {},
   "source": [
    "# Gerando os templates\n",
    "O método de rankeamento das palavras usado no PosNegTemplateGenerator é o Replace-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60dc1af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_generator.tasks.sentiment_analisys import PosNegTemplateGeneratorApp5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f595e69",
   "metadata": {},
   "source": [
    "### Número inicial de instâncias: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6261506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling instances\n",
    "np.random.seed(220)\n",
    "n_instances = 5\n",
    "df_sampled = imdb_df.sample(n_instances)\n",
    "\n",
    "instances = [x for x in df_sampled['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "660add17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting texts to sentences...\n",
      ":: 31 sentences were generated.\n",
      "Ranking words using Replace-1 Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3748665271fa>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Word ranking done.\n",
      "Filtering instances by contaning a minimmum of words: 5...\n",
      ":: 29 sentences remaining.\n",
      "Filtering instances by relevant words...\n",
      ":: 12 sentences remaining.\n",
      "Filtering instances by relevant words classification score greater than 0.8\n",
      ":: 2 sentences remaining.\n",
      "Predicting inputs...\n",
      ":: Sentence predictions done.\n"
     ]
    }
   ],
   "source": [
    "tg = PosNegTemplateGeneratorApp5(model, models)\n",
    "templates = tg.generate_templates(instances, n_masks=2, ranked_words_count=4, min_classification_score=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff5c8cb",
   "metadata": {},
   "source": [
    "#### Tempo de execução para 5 instâncias: 1m 15.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "193f1b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>template_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>They should have ditched the space station and headed for Mars.&lt;br /&gt;&lt;br /&gt;Major raspberries.</td>\n",
       "      <td>They {mask} have {mask} the space station and headed for Mars. &lt; br / &gt; &lt; br / &gt; Major raspberries .</td>\n",
       "      <td>They {neg_verb} have {neg_verb} the space station and headed for Mars. &lt; br / &gt; &lt; br / &gt; Major raspberries .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>God forgive me but I am just being honest.</td>\n",
       "      <td>God {mask} me but I am just being {mask} .</td>\n",
       "      <td>God {pos_adj} me but I am just being {pos_adj} .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      0   \n",
       "1      1   \n",
       "\n",
       "                                                                                   original_text  \\\n",
       "0  They should have ditched the space station and headed for Mars.<br /><br />Major raspberries.   \n",
       "1                                                     God forgive me but I am just being honest.   \n",
       "\n",
       "                                                                                            masked_text  \\\n",
       "0  They {mask} have {mask} the space station and headed for Mars. < br / > < br / > Major raspberries .   \n",
       "1                                                            God {mask} me but I am just being {mask} .   \n",
       "\n",
       "                                                                                                  template_text  \n",
       "0  They {neg_verb} have {neg_verb} the space station and headed for Mars. < br / > < br / > Major raspberries .  \n",
       "1                                                              God {pos_adj} me but I am just being {pos_adj} .  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tg.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c03851be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_verb': [],\n",
       " 'neg_verb': ['ditched', 'should'],\n",
       " 'pos_adj': ['honest', 'forgive'],\n",
       " 'neg_adj': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a27f1f",
   "metadata": {},
   "source": [
    "### Número inicial de instâncias: 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd4a7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using all 1000 instances\n",
    "instances = [x for x in imdb_df['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1f3f383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting texts to sentences...\n",
      ":: 7973 sentences were generated.\n",
      "Ranking words using Replace-1 Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3748665271fa>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Word ranking done.\n",
      "Filtering instances by contaning a minimmum of words: 5...\n",
      ":: 7621 sentences remaining.\n",
      "Filtering instances by relevant words...\n",
      ":: 2872 sentences remaining.\n",
      "Filtering instances by relevant words classification score greater than 0.8\n",
      ":: 276 sentences remaining.\n",
      "Predicting inputs...\n",
      ":: Sentence predictions done.\n"
     ]
    }
   ],
   "source": [
    "tg = PosNegTemplateGeneratorApp5(model, models)\n",
    "templates = tg.generate_templates(instances, n_masks=2, ranked_words_count=4, min_classification_score=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677154d8",
   "metadata": {},
   "source": [
    "#### Tempo de execução para 1000 instâncias: 272m 11.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c3c1541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>template_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>One should always have an open mind, and weigh all the options.</td>\n",
       "      <td>One {mask} always have an {mask} mind , and weigh all the options .</td>\n",
       "      <td>One {neg_verb} always have an {pos_adj} mind , and weigh all the options .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It takes someone of Chaplin's skill as a comedian to make something as dreary as trench warfare into such a brilliant comedy, but the irony that he uses in the film makes even the most uncomfortable conditions highly amusing.&lt;br /&gt;&lt;br /&gt;Like all of the best of Chaplin's films, short films and otherwise, this one is packed with brilliant and memorable scenes, such as the scene where he marks off kills with a piece of chalk on a board in the trench, erasing one when he gets his helmet shot off, the scene where he and his fellow soldiers are sleeping underwater, the opening of the beer bottle and lighting of the cigarette, and of course, the overtaking of the enemy.</td>\n",
       "      <td>It takes someone of Chaplin 's skill as a comedian to make something as dreary as trench warfare into such a brilliant comedy , but the irony that he uses in the film makes even the most uncomfortable conditions highly amusing. &lt; br / &gt; &lt; br / &gt; Like all of the {mask} of Chaplin 's films , short films and otherwise , this one is packed with brilliant and {mask} scenes , such as the scene where he marks off kills with a piece of chalk on a board in the trench , erasing one when he gets his helmet shot off , the scene where he and his fellow soldiers are sleeping underwater , the opening of the beer bottle and lighting of the cigarette , and of course , the overtaking of the enemy .</td>\n",
       "      <td>It takes someone of Chaplin 's skill as a comedian to make something as dreary as trench warfare into such a brilliant comedy , but the irony that he uses in the film makes even the most uncomfortable conditions highly amusing. &lt; br / &gt; &lt; br / &gt; Like all of the {pos_adj} of Chaplin 's films , short films and otherwise , this one is packed with brilliant and {pos_adj} scenes , such as the scene where he marks off kills with a piece of chalk on a board in the trench , erasing one when he gets his helmet shot off , the scene where he and his fellow soldiers are sleeping underwater , the opening of the beer bottle and lighting of the cigarette , and of course , the overtaking of the enemy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>This movie illustrates like no other the state of the Australian film industry and everything that's holding it back.&lt;br /&gt;&lt;br /&gt;Awesome talent, outstanding performances (particularly by Victoria Hill), but a let down in practically every other way.&lt;br /&gt;&lt;br /&gt;An \"adaptation\" of sorts, it brought nothing new to Macbeth (no, setting it in present-day Australia is not enough), and essentially, completely failed to justify its existence, apart from (let's face it, completely unnecessarily) paying homage to the original work.</td>\n",
       "      <td>This movie illustrates like no other the state of the Australian film industry and everything that 's holding it back. &lt; br / &gt; &lt; br / &gt; Awesome talent , {mask} performances ( particularly by Victoria Hill ) , but a let down in practically every other way. &lt; br / &gt; &lt; br / &gt; An `` adaptation '' of sorts , it brought nothing new to Macbeth ( no , setting it in present-day Australia is not enough ) , and essentially , completely {mask} to justify its existence , apart from ( let 's face it , completely unnecessarily ) paying homage to the original work .</td>\n",
       "      <td>This movie illustrates like no other the state of the Australian film industry and everything that 's holding it back. &lt; br / &gt; &lt; br / &gt; Awesome talent , {pos_adj} performances ( particularly by Victoria Hill ) , but a let down in practically every other way. &lt; br / &gt; &lt; br / &gt; An `` adaptation '' of sorts , it brought nothing new to Macbeth ( no , setting it in present-day Australia is not enough ) , and essentially , completely {neg_verb} to justify its existence , apart from ( let 's face it , completely unnecessarily ) paying homage to the original work .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>So any adaptation, if it's not to be a self-indulgent and pointless exercise, needs to at least bring some new interpretation to the work.&lt;br /&gt;&lt;br /&gt;And that's what this Macbeth fails to do.</td>\n",
       "      <td>So any adaptation , if it 's not to be a self-indulgent and {mask} exercise , needs to at least bring some new interpretation to the work. &lt; br / &gt; &lt; br / &gt; And that 's what this Macbeth {mask} to do .</td>\n",
       "      <td>So any adaptation , if it 's not to be a self-indulgent and {neg_adj} exercise , needs to at least bring some new interpretation to the work. &lt; br / &gt; &lt; br / &gt; And that 's what this Macbeth {neg_verb} to do .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>It's really too bad that nobody knows about this movie.</td>\n",
       "      <td>It 's really too {mask} that nobody {mask} about this movie .</td>\n",
       "      <td>It 's really too {neg_adj} that nobody {pos_verb} about this movie .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>1</td>\n",
       "      <td>Danson is outstanding as the title character and edward fox makes a wonderful villain.</td>\n",
       "      <td>Danson is {mask} as the title character and edward fox makes a {mask} villain .</td>\n",
       "      <td>Danson is {pos_adj} as the title character and edward fox makes a {pos_adj} villain .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>1</td>\n",
       "      <td>OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full</td>\n",
       "      <td>OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the {mask} show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the {mask} show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full</td>\n",
       "      <td>OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the {pos_adj} show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the {pos_adj} show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>1</td>\n",
       "      <td>The big budget special effects are spectacular but overshadowed by the jokes from the original comic.&lt;br /&gt;&lt;br /&gt;Depardieu and Clavier still work brilliantly as a pair while Monica Bellucci makes perfect casting as Cleopatra.</td>\n",
       "      <td>The big budget special effects are spectacular but overshadowed by the jokes from the original comic. &lt; br / &gt; &lt; br / &gt; Depardieu and Clavier still work brilliantly as a pair while Monica Bellucci makes {mask} {mask} as Cleopatra .</td>\n",
       "      <td>The big budget special effects are spectacular but overshadowed by the jokes from the original comic. &lt; br / &gt; &lt; br / &gt; Depardieu and Clavier still work brilliantly as a pair while Monica Bellucci makes {pos_adj} {neg_verb} as Cleopatra .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0</td>\n",
       "      <td>The only positive in the movie is the presence of some talented actors who did not help much text to explode their talents Finally.., iwant to know your comment about this movie guys... is it bad or what?</td>\n",
       "      <td>The {mask} positive in the movie is the presence of some talented actors who did not help much text to explode their talents Finally .. , iwant to know your comment about this movie guys ... is it {mask} or what ?</td>\n",
       "      <td>The {pos_adj} positive in the movie is the presence of some talented actors who did not help much text to explode their talents Finally .. , iwant to know your comment about this movie guys ... is it {neg_adj} or what ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1</td>\n",
       "      <td>The film is sentimental, and the last ten minutes could have been cut, but it was wonderfully entertaining.</td>\n",
       "      <td>The film {mask} sentimental , and the last ten minutes could have been {mask} , but it was wonderfully entertaining .</td>\n",
       "      <td>The film {neg_verb} sentimental , and the last ten minutes could have been {neg_verb} , but it was wonderfully entertaining .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  \\\n",
       "0        1   \n",
       "1        1   \n",
       "2        0   \n",
       "3        0   \n",
       "4        1   \n",
       "..     ...   \n",
       "271      1   \n",
       "272      1   \n",
       "273      1   \n",
       "274      0   \n",
       "275      1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          original_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       One should always have an open mind, and weigh all the options.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                       It takes someone of Chaplin's skill as a comedian to make something as dreary as trench warfare into such a brilliant comedy, but the irony that he uses in the film makes even the most uncomfortable conditions highly amusing.<br /><br />Like all of the best of Chaplin's films, short films and otherwise, this one is packed with brilliant and memorable scenes, such as the scene where he marks off kills with a piece of chalk on a board in the trench, erasing one when he gets his helmet shot off, the scene where he and his fellow soldiers are sleeping underwater, the opening of the beer bottle and lighting of the cigarette, and of course, the overtaking of the enemy.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       This movie illustrates like no other the state of the Australian film industry and everything that's holding it back.<br /><br />Awesome talent, outstanding performances (particularly by Victoria Hill), but a let down in practically every other way.<br /><br />An \"adaptation\" of sorts, it brought nothing new to Macbeth (no, setting it in present-day Australia is not enough), and essentially, completely failed to justify its existence, apart from (let's face it, completely unnecessarily) paying homage to the original work.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       So any adaptation, if it's not to be a self-indulgent and pointless exercise, needs to at least bring some new interpretation to the work.<br /><br />And that's what this Macbeth fails to do.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               It's really too bad that nobody knows about this movie.   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...   \n",
       "271                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Danson is outstanding as the title character and edward fox makes a wonderful villain.   \n",
       "272  OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full   \n",
       "273                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   The big budget special effects are spectacular but overshadowed by the jokes from the original comic.<br /><br />Depardieu and Clavier still work brilliantly as a pair while Monica Bellucci makes perfect casting as Cleopatra.   \n",
       "274                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        The only positive in the movie is the presence of some talented actors who did not help much text to explode their talents Finally.., iwant to know your comment about this movie guys... is it bad or what?   \n",
       "275                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         The film is sentimental, and the last ten minutes could have been cut, but it was wonderfully entertaining.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        masked_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               One {mask} always have an {mask} mind , and weigh all the options .   \n",
       "1                                                                                                                                                                                                                                                                                                                                                 It takes someone of Chaplin 's skill as a comedian to make something as dreary as trench warfare into such a brilliant comedy , but the irony that he uses in the film makes even the most uncomfortable conditions highly amusing. < br / > < br / > Like all of the {mask} of Chaplin 's films , short films and otherwise , this one is packed with brilliant and {mask} scenes , such as the scene where he marks off kills with a piece of chalk on a board in the trench , erasing one when he gets his helmet shot off , the scene where he and his fellow soldiers are sleeping underwater , the opening of the beer bottle and lighting of the cigarette , and of course , the overtaking of the enemy .   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     This movie illustrates like no other the state of the Australian film industry and everything that 's holding it back. < br / > < br / > Awesome talent , {mask} performances ( particularly by Victoria Hill ) , but a let down in practically every other way. < br / > < br / > An `` adaptation '' of sorts , it brought nothing new to Macbeth ( no , setting it in present-day Australia is not enough ) , and essentially , completely {mask} to justify its existence , apart from ( let 's face it , completely unnecessarily ) paying homage to the original work .   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         So any adaptation , if it 's not to be a self-indulgent and {mask} exercise , needs to at least bring some new interpretation to the work. < br / > < br / > And that 's what this Macbeth {mask} to do .   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     It 's really too {mask} that nobody {mask} about this movie .   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ...   \n",
       "271                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Danson is {mask} as the title character and edward fox makes a {mask} villain .   \n",
       "272  OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the {mask} show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the {mask} show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full   \n",
       "273                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         The big budget special effects are spectacular but overshadowed by the jokes from the original comic. < br / > < br / > Depardieu and Clavier still work brilliantly as a pair while Monica Bellucci makes {mask} {mask} as Cleopatra .   \n",
       "274                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The {mask} positive in the movie is the presence of some talented actors who did not help much text to explode their talents Finally .. , iwant to know your comment about this movie guys ... is it {mask} or what ?   \n",
       "275                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The film {mask} sentimental , and the last ten minutes could have been {mask} , but it was wonderfully entertaining .   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            template_text  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              One {neg_verb} always have an {pos_adj} mind , and weigh all the options .  \n",
       "1                                                                                                                                                                                                                                                                                                                                                 It takes someone of Chaplin 's skill as a comedian to make something as dreary as trench warfare into such a brilliant comedy , but the irony that he uses in the film makes even the most uncomfortable conditions highly amusing. < br / > < br / > Like all of the {pos_adj} of Chaplin 's films , short films and otherwise , this one is packed with brilliant and {pos_adj} scenes , such as the scene where he marks off kills with a piece of chalk on a board in the trench , erasing one when he gets his helmet shot off , the scene where he and his fellow soldiers are sleeping underwater , the opening of the beer bottle and lighting of the cigarette , and of course , the overtaking of the enemy .  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    This movie illustrates like no other the state of the Australian film industry and everything that 's holding it back. < br / > < br / > Awesome talent , {pos_adj} performances ( particularly by Victoria Hill ) , but a let down in practically every other way. < br / > < br / > An `` adaptation '' of sorts , it brought nothing new to Macbeth ( no , setting it in present-day Australia is not enough ) , and essentially , completely {neg_verb} to justify its existence , apart from ( let 's face it , completely unnecessarily ) paying homage to the original work .  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        So any adaptation , if it 's not to be a self-indulgent and {neg_adj} exercise , needs to at least bring some new interpretation to the work. < br / > < br / > And that 's what this Macbeth {neg_verb} to do .  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    It 's really too {neg_adj} that nobody {pos_verb} about this movie .  \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ...  \n",
       "271                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Danson is {pos_adj} as the title character and edward fox makes a {pos_adj} villain .  \n",
       "272  OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the {pos_adj} show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the {pos_adj} show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full stop.OZ is the greatest show ever mad full  \n",
       "273                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        The big budget special effects are spectacular but overshadowed by the jokes from the original comic. < br / > < br / > Depardieu and Clavier still work brilliantly as a pair while Monica Bellucci makes {pos_adj} {neg_verb} as Cleopatra .  \n",
       "274                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The {pos_adj} positive in the movie is the presence of some talented actors who did not help much text to explode their talents Finally .. , iwant to know your comment about this movie guys ... is it {neg_adj} or what ?  \n",
       "275                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         The film {neg_verb} sentimental , and the last ten minutes could have been {neg_verb} , but it was wonderfully entertaining .  \n",
       "\n",
       "[276 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tg.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b26cf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos_verb': ['Watching', 'inspired', 'finds', 'unfolds', 'knew', 'reckoned', 'love', 'Thank', 'touch', 'compelling', 'heartfelt', 'watched', 'knew.This', 'reunite', 'care', 'loved', 'lived', 'recreates', 'complimented', 'carries', 'appreciating', 'sings', 'sit', 'works', 'learned', 'enjoy', 'inspiring', 'choreographed', 'illustrating', 'email', 'stand', 'exists', 'amazing', 'watching', 'become', 'enjoyed', 'evokes', \"'ll\", 'exsists', 'appreciate', 'angles', 'wrenching', 'recommend', 'knows'], 'neg_verb': ['irritating', 'ignores', 'teeter', 'centered', 'costumed', 'disappears', 'had', 'panned', 'dumped', 'might', 'bashed', 'overacted', 'fail', 'waste', 'involved', 'comparing', 'fails', 'failed', 'wrecking', 'mean', 'waffling', 'operating', 'is', 'renting', 'stopped', 'seems', 'disappears.', 'crap', 'casting', 'been', 'should', 'broke', 'expecting', 'boring', 'scoff', 'padding', 'tries', 'spend', 'ditched', 'grating', 'lack', 'mentioned', 'cringed', 'avoid', 'suck', 'hires', 'could', 'sickening', 'bored', 'Christians', 'skip', 'was', 'replaced', 'pretends', 'suggests', 'stop', 'Wasted', 'annoying', 'forget', \"'s\", 'directed', 'going', 'hate', 'wasted', 'wait', 'mighta', 'were', 'acting', 'IS', 'Insinuated', 'looking', 'did', 'cut', 'degrading', 'be', 'ruined', 'would', 'seen'], 'pos_adj': ['heartfelt.', 'rare', 'cathartic', 'flawless', 'black-comedy', 'sci-fi', 'modern', 'unique', 'spirited', 'essential', 'melodic', 'funniest', 'emotional', 'elegant', 'well-crafted', 'extraordinary', 'palpable', 'good', 'multi-millionaire', 'unusual', 'animated', 'exemplary', 'worth', 'noir', 'memorable', 'simple', 'classic', 'outstanding', 'remarkable', 'hilarious', 'solid', 'hilarious.', 'tremendous', 'great', 'terrific', 'smooth', 'life.', 'Incredible', 'ambient', 'Spanish/Portuguese', 'amazing', 'vivid', 'nice', 'Sci-Fi', 'cartoonish', 'adorable', 'happy', 'excellent', 'musical', 'Wonderful', 'awesome', 'good-looking', 'greatest', 'Fantastic', 'prurient.', 'light-hearted', 'best', 'nostalgic', 'watchable', 'fantastic', 'direct-to-video', 'positive', 'unbeatable', 'only', 'honest', 'perfect', 'sexy', 'suspenseful', 'Lovecraftian', 'likable', 'romantic', 'emotive', 'well-endowed', 'flamboyant', 'believable', 'authentic', 'indispensable', 'incredible', 'forgive', 'inspiring', 'brilliant', 'upbeat', 'hot', 'tight', 'intense', 'genuine', 'film-making', 'welcome', 'open', 'wonderful'], 'neg_adj': ['spare', 'unfunny', 'cannibal', 'obnoxious', 'tacky', 'half-hour', 'horrendous', 'regrettable', 'moribund', 'worst', 'unoriginal', 'opposite', 'clumsy', 'dysfunctional', 'garishly', 'loud', 'forgettable.', 'bad-movie', 'unintentionally', 'disappointed', 'abusive', 'dumb', 'laughable', 'manipulative', 'horrible', 'repulsive', 'trite', 'adequate', 'locations-person', 'suck-ful', 'few', 'cookie-cutter', 'absurd', 'nasty', 'cheapest', 'boring', 'hulky', 'turgid', 'fake', 'senseless', 'ridiculous', 'lame', 'mercenary', 'Terrible', 'predictable', 'awful', 'yet-another-so-called-sequel.', 'dull', 'head-banging', 'disappointed.', 'overused', 'crappiest', 'biased', 'promising', 'poor', 'amateurish.Two', 'middle-aged', 'narcissistic', 'scruffy', 'tiresome', 'pre-Code', 'bad', 'unrealistic', 'cheap', 'hollow', 'atrocious', 'unpleasant', 'painful', 'unfortunate', 'officer/bad', 'sick', 'alien', 'false', 'unconvincing', 'better', 'disastrous', 'rubbish.', 'embarrassing', 'umption', 'worse', 'clichéd', 'annoying', 'imaginable', 'inarticulate', 'unlikable', 'ugliness', 'initial', 'soppy', 'tedious', 'incomprehensible', 'dreadful', 'putrid', 'stereotypical', 'stupid', 'pointless', 'terrible', 'crappy']}\n"
     ]
    }
   ],
   "source": [
    "print(tg.lexicons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b218563",
   "metadata": {},
   "source": [
    "# Usando os templates gerados pelo TemplateGenerator no CheckList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "535bea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.editor import Editor\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.test_types import MFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "247a1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicons = tg.lexicons\n",
    "templates = tg.template_texts\n",
    "masked = tg.masked_texts\n",
    "labels = [sent.prediction.label for sent in tg.sentences]\n",
    "\n",
    "editor = Editor()\n",
    "editor.add_lexicon('pos_verb', lexicons['pos_verb'])\n",
    "editor.add_lexicon('neg_verb', lexicons['neg_verb'])\n",
    "editor.add_lexicon('pos_adj', lexicons['pos_adj'])\n",
    "editor.add_lexicon('neg_adj', lexicons['neg_adj'])\n",
    "\n",
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b233f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for template, label, i in zip(templates, labels, range(len(templates))):\n",
    "    t = editor.template(template, remove_duplicates=True, labels=int(label))\n",
    "\n",
    "    suite.add(MFT(\n",
    "        data=t.data,\n",
    "        labels=label,\n",
    "        capability=\"Vocabullary\", \n",
    "        name=f\"Test: MFT with vocabullary - template{i+1}\",\n",
    "        description=\"Checking if the model can handle vocabullary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63e25aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: MFT with vocabullary - template1\n",
      "Predicting 7020 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3748665271fa>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: MFT with vocabullary - template2\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template3\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template4\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template5\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template6\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template7\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template8\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template9\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template10\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template11\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template12\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template13\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template14\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template15\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template16\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template17\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template18\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template19\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template20\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template21\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template22\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template23\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template24\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template25\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template26\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template27\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template28\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template29\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template30\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template31\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template32\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template33\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template34\n",
      "Predicting 3432 examples\n",
      "Running Test: MFT with vocabullary - template35\n",
      "Predicting 3432 examples\n",
      "Running Test: MFT with vocabullary - template36\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template37\n",
      "Predicting 44 examples\n",
      "Running Test: MFT with vocabullary - template38\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template39\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template40\n",
      "Predicting 3432 examples\n",
      "Running Test: MFT with vocabullary - template41\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template42\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template43\n",
      "Predicting 3432 examples\n",
      "Running Test: MFT with vocabullary - template44\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template45\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template46\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template47\n",
      "Predicting 44 examples\n",
      "Running Test: MFT with vocabullary - template48\n",
      "Predicting 3432 examples\n",
      "Running Test: MFT with vocabullary - template49\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template50\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template51\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template52\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template53\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template54\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template55\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template56\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template57\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template58\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template59\n",
      "Predicting 3432 examples\n",
      "Running Test: MFT with vocabullary - template60\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template61\n",
      "Predicting 44 examples\n",
      "Running Test: MFT with vocabullary - template62\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template63\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template64\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template65\n",
      "Predicting 44 examples\n",
      "Running Test: MFT with vocabullary - template66\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template67\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template68\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template69\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template70\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template71\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template72\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template73\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template74\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template75\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template76\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template77\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template78\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template79\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template80\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template81\n",
      "Predicting 3432 examples\n",
      "Running Test: MFT with vocabullary - template82\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template83\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template84\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template85\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template86\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template87\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template88\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template89\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template90\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template91\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template92\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template93\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template94\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template95\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template96\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template97\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template98\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template99\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template100\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template101\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template102\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template103\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template104\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template105\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template106\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template107\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template108\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template109\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template110\n",
      "Predicting 3432 examples\n",
      "Running Test: MFT with vocabullary - template111\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template112\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template113\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template114\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template115\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template116\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template117\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template118\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template119\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template120\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template121\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template122\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template123\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template124\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template125\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template126\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template127\n",
      "Predicting 3432 examples\n",
      "Running Test: MFT with vocabullary - template128\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template129\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template130\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template131\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template132\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template133\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template134\n",
      "Predicting 44 examples\n",
      "Running Test: MFT with vocabullary - template135\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template136\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template137\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template138\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template139\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template140\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template141\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template142\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template143\n",
      "Predicting 44 examples\n",
      "Running Test: MFT with vocabullary - template144\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template145\n",
      "Predicting 3432 examples\n",
      "Running Test: MFT with vocabullary - template146\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template147\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template148\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template149\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template150\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template151\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template152\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template153\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template154\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template155\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template156\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template157\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template158\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template159\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template160\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template161\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template162\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template163\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template164\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template165\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template166\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template167\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template168\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template169\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template170\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template171\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template172\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template173\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template174\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template175\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template176\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template177\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template178\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template179\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template180\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template181\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template182\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template183\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template184\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template185\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template186\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template187\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template188\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template189\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template190\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template191\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template192\n",
      "Predicting 3432 examples\n",
      "Running Test: MFT with vocabullary - template193\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template194\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template195\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template196\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template197\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template198\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template199\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template200\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template201\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template202\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template203\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template204\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template205\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template206\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template207\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template208\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template209\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template210\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template211\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template212\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template213\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template214\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template215\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template216\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template217\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template218\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template219\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template220\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template221\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template222\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template223\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template224\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template225\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template226\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template227\n",
      "Predicting 3432 examples\n",
      "Running Test: MFT with vocabullary - template228\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template229\n",
      "Predicting 3432 examples\n",
      "Running Test: MFT with vocabullary - template230\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template231\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template232\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template233\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template234\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template235\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template236\n",
      "Predicting 3432 examples\n",
      "Running Test: MFT with vocabullary - template237\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template238\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template239\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template240\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template241\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template242\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template243\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template244\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template245\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template246\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template247\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template248\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template249\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template250\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template251\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template252\n",
      "Predicting 78 examples\n",
      "Running Test: MFT with vocabullary - template253\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template254\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template255\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template256\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template257\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template258\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template259\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template260\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template261\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template262\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template263\n",
      "Predicting 3958 examples\n",
      "Running Test: MFT with vocabullary - template264\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template265\n",
      "Predicting 4268 examples\n",
      "Running Test: MFT with vocabullary - template266\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template267\n",
      "Predicting 97 examples\n",
      "Running Test: MFT with vocabullary - template268\n",
      "Predicting 7564 examples\n",
      "Running Test: MFT with vocabullary - template269\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template270\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template271\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template272\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template273\n",
      "Predicting 90 examples\n",
      "Running Test: MFT with vocabullary - template274\n",
      "Predicting 7020 examples\n",
      "Running Test: MFT with vocabullary - template275\n",
      "Predicting 8730 examples\n",
      "Running Test: MFT with vocabullary - template276\n",
      "Predicting 78 examples\n"
     ]
    }
   ],
   "source": [
    "suite.run(model.predict, overwrite=True)\n",
    "suite.save('./suites/posneg-approach5.suite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea634cbe",
   "metadata": {},
   "source": [
    "# Carregando suite de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "526171ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e6e9eb30354be595ba92844f32e599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'Test: MFT with vocab…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from checklist.test_suite import TestSuite\n",
    "suite = TestSuite.from_file('./suites/posneg-approach5.suite')\n",
    "\n",
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pressed-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = suite.visual_summary_by_test('Test: MFT with vocabullary - template3')\n",
    "\n",
    "for item in table.candidate_testcases:\n",
    "    print(item['examples'][0]['new']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-voluntary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tcc-adson')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba94d9933593690a16dfd143f91f6142bfaed0bcefffd4b370c30be1be212c38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
