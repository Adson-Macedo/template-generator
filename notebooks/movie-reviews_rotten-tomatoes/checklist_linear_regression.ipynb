{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GniN6LjphLS"
   },
   "source": [
    "# Checklist - Análise de Sentimentos IMDB\n",
    "### SckitLearn Model Logistic Regression\n",
    "\n",
    "Author: Felipe Thamay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dtY4ONRXphLb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\felipe\\anaconda3\\envs\\checklist3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "import model_linear_regression\n",
    "import checklist\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.expect import Expect\n",
    "from checklist.pred_wrapper import PredictorWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liweEgyIphL1"
   },
   "source": [
    "#### MFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omAnWmyqphL1"
   },
   "source": [
    "O modelo deve ser capaz de distinguir questões relacionadas a emoções positivas e negativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SMuiGb9c5_s2"
   },
   "outputs": [],
   "source": [
    "suite = TestSuite()\n",
    "editor = Editor(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Yuvvj5nyphL2"
   },
   "outputs": [],
   "source": [
    "film_noun = ['story', 'tale', 'description', 'picture', 'sketch', 'painting', 'narrative', 'panel', 'narrative', 'report',\n",
    "'report', 'fable', 'outline', 'portrait', 'trace', 'review', 'grove', 'relation', 'tradition', 'novel', 'story',\n",
    "'exhibition', 'saga', 'raconto', 'drawing', 'outline', 'record', 'fiction', 'biography', 'legend', 'guide', 'script', 'defeat',\n",
    "'route', 'script', 'itinerary', 'novelist', 'novelist', 'historian', 'narrator', 'chronist', 'humorist', 'story writer', 'anesdotista',\n",
    "'Biographer', 'Adventure', 'Biographic', 'Comedy', 'Dramatic Comedy', 'Romantic Comedy', 'Historical', 'Drama', 'Action',\n",
    "'Science fiction', 'Horror']\n",
    "editor.add_lexicon('film_noun', film_noun, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jbigfIqjphL2"
   },
   "outputs": [],
   "source": [
    "pos_adj = ['good','wonderful','pleasure','pleasant','surprising','funny','great','excellent','amazing',\n",
    "             'extraordinary','beautiful','fantastic','exceptional','perfect','fun','happy','lovely',\n",
    "             'brilliant','exciting', 'sweet','wonderful','ok']\n",
    "editor.add_lexicon('pos_adj', pos_adj, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yC7h6NT6phL2"
   },
   "outputs": [],
   "source": [
    "neg_adj = ['boring','tiring','monotonous','bad','terrible',\"didn't like it\",'awful','cliché','tiring',\n",
    "             'strange', 'rough', 'terrible','unfortunate','average','difficult','poor','sad','frustrating',\n",
    "             'difficult','lame','nasty','annoying','frightening','terrible','ridiculous','terrible','ugly',\n",
    "             'unpleasant']\n",
    "editor.add_lexicon('neg_adj', neg_adj, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_DDtXZdnphL2"
   },
   "outputs": [],
   "source": [
    "neutral_adj = ['American','international','commercial','British','private','Italian','Indian','Australian',\n",
    "                'Israeli','Brazilian']\n",
    "editor.add_lexicon('neutral_adj', neutral_adj, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LE2OP-cDphL3"
   },
   "outputs": [],
   "source": [
    "article = ['o','a','os','as']\n",
    "editor.add_lexicon('article', article, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WDQ0U2LpphL3"
   },
   "outputs": [],
   "source": [
    "pos_verb_present = ['like','enjoy','appreciate','love','recommend','admire','value','welcome']\n",
    "neg_verb_present = ['hate','dislike','repent','hate','dread','dislike']\n",
    "neutral_verb_present = ['see','find']\n",
    "pos_verb_past = ['liked','appreciated','loved','admired','valued']\n",
    "neg_verb_past = ['hated',\"didn't like it\",'sorry','feared','disdained']\n",
    "neutral_verb_past = ['saw','found']\n",
    "demo_pron = ['This','This','This','This','That','That']\n",
    "pred = ['is', 'was', 'like']\n",
    "pers_pron = ['I','You','He','We','You','They']\n",
    "                 \n",
    "editor.add_lexicon('pos_verb_present', pos_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neg_verb_present', neg_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb_present', neutral_verb_present, overwrite=True)\n",
    "editor.add_lexicon('pos_verb_past', pos_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neg_verb_past', neg_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb_past', neutral_verb_past, overwrite=True)\n",
    "editor.add_lexicon('pos_verb', pos_verb_present+ pos_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neg_verb', neg_verb_present + neg_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb', neutral_verb_present + neutral_verb_past, overwrite=True)\n",
    "editor.add_lexicon('demo_pron', demo_pron, overwrite=True)\n",
    "editor.add_lexicon('pred', pred, overwrite=True)\n",
    "editor.add_lexicon('pers_pron', pers_pron, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xVeMNhmQrlIF"
   },
   "outputs": [],
   "source": [
    "t = editor.template(\n",
    "    '{demo_pron} {film_noun} {pred} {pos_adj}.', \n",
    "    remove_duplicates=True, \n",
    "    nsamples=300, \n",
    "    labels=1)\n",
    "\n",
    "test = MFT(\n",
    "    **t, name='Palavras carregadas de sentimento no contexto', \n",
    "    capability = 'NER',\n",
    "    description='Retorne positivo ou negativo, mesmo que tenha erro de digitação')\n",
    "\n",
    "suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "M7j0xRX3phL3"
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(model_linear_regression.vect, model_linear_regression.model_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vX1Ux8e0GiNv"
   },
   "outputs": [],
   "source": [
    "# PredictorWrapper\n",
    "predictor = PredictorWrapper().wrap_softmax(pipe.predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "referenced_widgets": [
      "b9fcd4829de64b84be79c897a840095c"
     ]
    },
    "id": "aa1rxInh_5bN",
    "outputId": "e7d8de46-aa90-4594-dd6a-4fa8f7e51691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Palavras carregadas de sentimento no contexto\n",
      "Predicting 300 examples\n",
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48bec14f4a7542ef84361308f2f91fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'Palavras carregadas …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite.run(predictor, overwrite=True)\n",
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-Tohc65ETnx"
   },
   "source": [
    "### INV (INVariance test - Teste de invariância)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0KpiMjyphL4"
   },
   "source": [
    "Se você tiver duas frases com a mesma entidade nomeada, alterar a entidade em ambas não deve alterar se as perguntas são duplicadas ou não.\n",
    "Vamos escrever um INV para isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "O78N_QSyphL5"
   },
   "outputs": [],
   "source": [
    "neutral_words = set(\n",
    "    ['.','o','O',',','a','A','and','from','to','this','that','in',' this','to',\n",
    "      'you','there','or','a','by','on','film','mine','in','from','has','with','was ',\n",
    "      'in','this','get','from','this','American','international','commercial',\n",
    "      'British','private','Italian','Indian','Australian','Israeli','Brazilian',\n",
    "      'see','find','saw','found'])\n",
    "forbidden = set(['No','no','No','no','Nothing','nothing','without','but'] + pos_adj + neg_adj + pos_verb_present \n",
    "                + pos_verb_past + neg_verb_present + neg_verb_past)\n",
    "def change_neutral(d):\n",
    "    examples = []\n",
    "    subs = []\n",
    "    words_in = [x for x in d.capitalize().split() if x in neutral_words]\n",
    "    if not words_in:\n",
    "        return None\n",
    "    for w in words_in:\n",
    "        suggestions = [x for x in editor.suggest_replace(d, w, beam_size=5, words_and_sentences=True) if x[0] not in forbidden]\n",
    "        examples.extend([x[1] for x in suggestions])\n",
    "        subs.extend(['%s -> %s' % (w, x[0]) for x in suggestions])\n",
    "    if examples:\n",
    "        idxs = np.random.choice(len(examples), min(len(examples), 10), replace=False)\n",
    "        return [examples[i] for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "referenced_widgets": [
      "e7a2c7c2c42c451ba926e572f45d4b90"
     ]
    },
    "id": "y1paZsOsphL5",
    "outputId": "5ab2fb3b-d659-4031-b791-401d2e7120f5"
   },
   "outputs": [],
   "source": [
    "t = Perturb.perturb(\n",
    "    model_linear_regression.df_test.review.array, \n",
    "    Perturb.add_typos, \n",
    "    nsamples=200, \n",
    "    typos=3)\n",
    "\n",
    "test = INV(\n",
    "    **t, \n",
    "    name='Mude palavras neutras com BERT', \n",
    "    capability='NER', \n",
    "    description='Altere um conjunto de palavras neutras por outras palavras neutras apropriadas ao contexto')\n",
    "\n",
    "suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Palavras carregadas de sentimento no contexto\n",
      "Predicting 300 examples\n",
      "Running Mude palavras neutras com BERT\n",
      "Predicting 400 examples\n",
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fd46888eef419b83738922d96f1d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'Palavras carregadas …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite.run(predictor, overwrite=True)\n",
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJXfu7aGETnz"
   },
   "source": [
    "### DIR (DIRectional expectation test - Teste de expectativa direcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nQ7u5sVUphL6"
   },
   "outputs": [],
   "source": [
    "df0 = model_linear_regression.df_test[model_linear_regression.df_test['sentiment'] == 'neg']\n",
    "df1= model_linear_regression.df_test[model_linear_regression.df_test['sentiment'] == 'pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CPmAwiuhETn1"
   },
   "outputs": [],
   "source": [
    "expect_fn = Expect.monotonic(label=1, increasing=True, tolerance=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1CqRZtGKETn2"
   },
   "outputs": [],
   "source": [
    "t = Perturb.perturb(\n",
    "    df1.review.array, \n",
    "    Perturb.add_typos, \n",
    "    nsamples=200)\n",
    "name = 'Mudar o nome em uma das questões'\n",
    "desc = 'Pegue os pares que foram originalmente previstos como duplicados, altere o nome em um deles e espere que a nova previsão não seja duplicada'\n",
    "\n",
    "test = DIR(\n",
    "    **t, \n",
    "    expect=expect_fn, \n",
    "    name=name, \n",
    "    description=desc, \n",
    "    capability='NER')\n",
    "\n",
    "suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LB6_WfJTphL7",
    "outputId": "a9ffa394-5b12-4563-9a9e-30b5e8ec6d3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Palavras carregadas de sentimento no contexto\n",
      "Predicting 300 examples\n",
      "Running Mude palavras neutras com BERT\n",
      "Predicting 400 examples\n",
      "Running Mudar o nome em uma das questões\n",
      "Predicting 400 examples\n",
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a7b25f1640478dbe2d7945837dd47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'Palavras carregadas …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite.run(predictor, overwrite=True)\n",
    "suite.visual_summary_table()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Análise_de_Sentimentos_IMDB3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "b9fcd4829de64b84be79c897a840095c": {
     "model_module": "viewer",
     "model_name": "SuiteSummarizerModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "viewer",
      "_model_module_version": "^0.1.0",
      "_model_name": "SuiteSummarizerModel",
      "_view_count": null,
      "_view_module": "viewer",
      "_view_module_version": "^0.1.0",
      "_view_name": "SuiteSummarizerView",
      "layout": "IPY_MODEL_4da6e57c228748b3aafcd313e7cf28d4",
      "stats": {
       "nfailed": 0,
       "nfiltered": 0,
       "npassed": 0
      },
      "summarizer": {},
      "test_infos": [
       {
        "capability": "NER",
        "description": "Retorne positivo ou negativo, mesmo que tenha erro de digitação",
        "name": "Palavras carregadas de sentimento no contexto",
        "stats": {
         "nfailed": 158,
         "nfiltered": 0,
         "npassed": 142
        },
        "tags": [],
        "type": "mft"
       }
      ],
      "testcases": []
     }
    },
    "e7a2c7c2c42c451ba926e572f45d4b90": {
     "model_module": "viewer",
     "model_name": "SuiteSummarizerModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "viewer",
      "_model_module_version": "^0.1.0",
      "_model_name": "SuiteSummarizerModel",
      "_view_count": null,
      "_view_module": "viewer",
      "_view_module_version": "^0.1.0",
      "_view_name": "SuiteSummarizerView",
      "layout": "IPY_MODEL_2df81f42c47e489086b335545f8d2426",
      "stats": {
       "nfailed": 0,
       "nfiltered": 0,
       "npassed": 0
      },
      "summarizer": {},
      "test_infos": [
       {
        "capability": "NER",
        "description": "Retorne positivo ou negativo, mesmo que tenha erro de digitação",
        "name": "Palavras carregadas de sentimento no contexto",
        "stats": {
         "nfailed": 158,
         "nfiltered": 0,
         "npassed": 142
        },
        "tags": [],
        "type": "mft"
       },
       {
        "capability": "NER",
        "description": "Altere um conjunto de palavras neutras por outras palavras neutras apropriadas ao contexto",
        "name": "Mude palavras neutras com BERT",
        "stats": {
         "nfailed": 1,
         "nfiltered": 0,
         "npassed": 199
        },
        "tags": [],
        "type": "inv"
       }
      ],
      "testcases": []
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
