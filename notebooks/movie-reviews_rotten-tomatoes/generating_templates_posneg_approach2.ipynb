{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e2c728",
   "metadata": {},
   "source": [
    "# Abordagem 2\n",
    "\n",
    "Usando a abordagem 2 para gerar templates com foco em templates positivos e negativos. Uma possível aplicação seria testar a capacidade linguística *Vocabullary* com o teste **MFT**.\n",
    "\n",
    "As etapas desta abordagem são:\n",
    "\n",
    "1. Rankear as palavras das instâncias completas\n",
    "2. Quebrar as instâncias em sentenças\n",
    "3. Filtrar as sentenças que contêm ao menos uma das palavras mais bem rankeadas na etapa anterior\n",
    "4. Rankear as palavras de cada sentença\n",
    "5. Filtrar as sentenças com palavras relevantes (adjetivos ou verbos)\n",
    "6. Classificar as sentenças usando o *Oráculo*\n",
    "7. Substituir as palavras relevantes por máscaras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897c3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da847fc",
   "metadata": {},
   "source": [
    "## Carregando o dataset, o modelo alvo e os modelos auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e018fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>allen's underestimated charm delivers more goodies than lumps of coal .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>skip the film and buy the philip glass soundtrack cd .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>involving at times  but lapses quite casually into the absurd .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>while hoffman's performance is great  the subject matter goes nowhere .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>a flick about our infantilized culture that isn't entirely infantile .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      1   \n",
       "1      0   \n",
       "2      0   \n",
       "3      0   \n",
       "4      1   \n",
       "\n",
       "                                                                       text  \\\n",
       "0  allen's underestimated charm delivers more goodies than lumps of coal .    \n",
       "1                   skip the film and buy the philip glass soundtrack cd .    \n",
       "2          involving at times  but lapses quite casually into the absurd .    \n",
       "3  while hoffman's performance is great  the subject matter goes nowhere .    \n",
       "4   a flick about our infantilized culture that isn't entirely infantile .    \n",
       "\n",
       "   words  \n",
       "0     11  \n",
       "1     11  \n",
       "2     11  \n",
       "3     11  \n",
       "4     11  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "movie_reviews_rt_df = pd.read_csv('./data/data-rt-100samples.csv')\n",
    "movie_reviews_rt_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264d0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "def pre_proccess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[\"\\',!-.:-@0-9/]()', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Wrapper to adapt output format\n",
    "class SentimentAnalisysModelWrapper:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __predict(self, text_input):\n",
    "        text_preprocessed = pre_proccess(text_input)\n",
    "        tokenized = self.tokenizer(text_preprocessed, padding=True, truncation=True, max_length=512, \n",
    "                                    add_special_tokens = True, return_tensors=\"pt\")\n",
    "        \n",
    "        tensor_logits = self.model(**tokenized)\n",
    "        prob = softmax(tensor_logits[0]).detach().numpy()\n",
    "        pred = np.argmax(prob)\n",
    "        \n",
    "        return pred, prob\n",
    "    \n",
    "    def predict_label(self, text_inputs):\n",
    "        return self.predict(text_inputs)[0]\n",
    "        \n",
    "    def predict_proba(self, text_inputs):\n",
    "        return self.predict(text_inputs)[1]\n",
    "        \n",
    "    def predict(self, text_inputs):\n",
    "        if isinstance(text_inputs, str):\n",
    "            text_inputs = [text_inputs]\n",
    "        \n",
    "        preds = []\n",
    "        probs = []\n",
    "\n",
    "        for text_input in text_inputs:\n",
    "            pred, prob = self.__predict(text_input)\n",
    "            preds.append(pred)\n",
    "            probs.append(prob[0])\n",
    "\n",
    "        return np.array(preds), np.array(probs) # ([0, 1], [[0.99, 0.01], [0.03, 0.97]])\n",
    "\n",
    "# Auxiliar function to load and wrap a model from Hugging Face\n",
    "def load_model(model_name):\n",
    "    print(f'Loading model {model_name}...')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    return SentimentAnalisysModelWrapper(model, tokenizer)\n",
    "\n",
    "# Hugging Face hosted model names \n",
    "movie_reviews_models = {\n",
    "    'bert': 'textattack/bert-base-uncased-rotten-tomatoes', \n",
    "    'albert': 'textattack/albert-base-v2-rotten-tomatoes', \n",
    "    'distilbert': 'textattack/distilbert-base-uncased-rotten-tomatoes', \n",
    "    'roberta': 'textattack/roberta-base-rotten-tomatoes', \n",
    "    'xlnet': 'textattack/xlnet-base-cased-rotten-tomatoes'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f271eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model textattack/albert-base-v2-rotten-tomatoes...\n",
      "Loading model textattack/distilbert-base-uncased-rotten-tomatoes...\n",
      "Loading model textattack/roberta-base-rotten-tomatoes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-rotten-tomatoes were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model textattack/xlnet-base-cased-rotten-tomatoes...\n",
      "Loading model textattack/bert-base-uncased-rotten-tomatoes...\n"
     ]
    }
   ],
   "source": [
    "m1 = load_model(movie_reviews_models['albert'])\n",
    "m2 = load_model(movie_reviews_models['distilbert'])\n",
    "m3 = load_model(movie_reviews_models['roberta'])\n",
    "m4 = load_model(movie_reviews_models['xlnet'])\n",
    "\n",
    "# Models to be used as oracle\n",
    "models = [m1, m2, m3, m4]\n",
    "# Target model\n",
    "model = load_model(movie_reviews_models['bert'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae89b5",
   "metadata": {},
   "source": [
    "# Gerando os templates\n",
    "O método de rankeamento das palavras usado no PosNegTemplateGenerator é o Replace-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60dc1af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_generator.tasks.sentiment_analisys import PosNegTemplateGeneratorApp2\n",
    "\n",
    "tg = PosNegTemplateGeneratorApp2(model, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f595e69",
   "metadata": {},
   "source": [
    "### Número inicial de instâncias: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6261506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling instances\n",
    "np.random.seed(220)\n",
    "n_instances = 5\n",
    "df_sampled = movie_reviews_rt_df.sample(n_instances)\n",
    "\n",
    "instances = [x for x in df_sampled['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "660add17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking words using Replace-1 Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-263ca9d23a33>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting texts to sentences...\n",
      ":: 6 sentences were generated.\n",
      "Filtering instances by contaning ranked words...\n",
      ":: 1 sentences remaining.\n",
      "Ranking words using Replace-1 Score...\n",
      ":: Word ranking done.\n",
      "4\n",
      "Filtering instances by relevant words...\n",
      "['VERB', 'ADJ']\n",
      "{word: future, index: 2, tag: NOUN, rank_score: -0.06550866365432739}\n",
      "{word: hopes, index: 4, tag: VERB, rank_score: -0.0017756223678588867}\n",
      "{word: one, index: 3, tag: NUM, rank_score: 0.0016388297080993652}\n",
      "{word: for, index: 0, tag: ADP, rank_score: 0.0016148090362548828}\n",
      " \n",
      ":: 0 sentences remaining.\n",
      "Predicting inputs...\n",
      ":: Sentence predictions done.\n"
     ]
    }
   ],
   "source": [
    "templates = tg.generate_templates(instances, n_masks=2, ranked_words_count=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d150cb",
   "metadata": {},
   "source": [
    "#### Tempo de execução para 5 instâncias: 9.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "193f1b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>template_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, original_text, masked_text, template_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tg.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f98d8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_verb': [], 'neg_verb': [], 'pos_adj': [], 'neg_adj': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a27f1f",
   "metadata": {},
   "source": [
    "### Número inicial de instâncias: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd4a7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using all 100 instances\n",
    "instances = [x for x in movie_reviews_rt_df['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1f3f383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking words using Replace-1 Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-263ca9d23a33>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting texts to sentences...\n",
      ":: 134 sentences were generated.\n",
      "Filtering instances by contaning ranked words...\n",
      ":: 23 sentences remaining.\n",
      "Ranking words using Replace-1 Score...\n",
      ":: Word ranking done.\n",
      "4\n",
      "Filtering instances by relevant words...\n",
      "['VERB', 'ADJ']\n",
      "{word: clunker, index: 11, tag: NOUN, rank_score: -0.0016779303550720215}\n",
      "{word: a, index: 4, tag: DET, rank_score: -0.0002397298812866211}\n",
      "{word: well-made, index: 5, tag: ADJ, rank_score: -0.00020068883895874023}\n",
      "{word: thoughtful, index: 6, tag: ADJ, rank_score: -0.0001347064971923828}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: this, index: 9, tag: DET, rank_score: -0.0038509368896484375}\n",
      "{word: regard, index: 10, tag: NOUN, rank_score: 0.002340257167816162}\n",
      "{word: guard, index: 12, tag: NOUN, rank_score: 0.0020131468772888184}\n",
      "{word: on, index: 11, tag: ADP, rank_score: 0.0017519593238830566}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: trailers, index: 10, tag: NOUN, rank_score: -0.004239559173583984}\n",
      "{word: bad, index: 7, tag: ADJ, rank_score: -0.0035950541496276855}\n",
      "{word: could, index: 0, tag: VERB, rank_score: 0.0003083348274230957}\n",
      "{word: as, index: 6, tag: ADV, rank_score: -0.0002740025520324707}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: awful, index: 11, tag: NOUN, rank_score: -0.8138947486877441}\n",
      "{word: pauly, index: 9, tag: ADV, rank_score: -0.008067667484283447}\n",
      "{word: it, index: 7, tag: PRON, rank_score: -0.003497779369354248}\n",
      "{word: 's, index: 8, tag: VERB, rank_score: 0.0024172067642211914}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: you, index: 16, tag: PRON, rank_score: -0.64985591173172}\n",
      "{word: n't, index: 14, tag: ADV, rank_score: -0.6476182341575623}\n",
      "{word: warned, index: 19, tag: VERB, rank_score: -0.645062267780304}\n",
      "{word: ., index: 20, tag: ., rank_score: -0.6448526978492737}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: love, index: 17, tag: VERB, rank_score: -0.978091299533844}\n",
      "{word: you, index: 14, tag: PRON, rank_score: -0.023657381534576416}\n",
      "{word: probably, index: 16, tag: ADV, rank_score: 0.009064733982086182}\n",
      "{word: 'll, index: 15, tag: VERB, rank_score: 0.0070650577545166016}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: marks, index: 15, tag: NOUN, rank_score: -0.8324263691902161}\n",
      "{word: should, index: 17, tag: VERB, rank_score: -0.8276894092559814}\n",
      "{word: it, index: 16, tag: PRON, rank_score: -0.8192701935768127}\n",
      "{word: all, index: 12, tag: DET, rank_score: -0.7217094302177429}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: and, index: 7, tag: CONJ, rank_score: -0.0007128715515136719}\n",
      "{word: vengeance, index: 17, tag: NOUN, rank_score: -0.00013494491577148438}\n",
      "{word: monsters, index: 12, tag: NOUN, rank_score: -0.00012129545211791992}\n",
      "{word: scary, index: 8, tag: ADJ, rank_score: -6.514787673950195e-05}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: future, index: 2, tag: NOUN, rank_score: -0.06550866365432739}\n",
      "{word: hopes, index: 4, tag: VERB, rank_score: -0.0017756223678588867}\n",
      "{word: one, index: 3, tag: NUM, rank_score: 0.0016388297080993652}\n",
      "{word: for, index: 0, tag: ADP, rank_score: 0.0016148090362548828}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: nothing, index: 20, tag: NOUN, rank_score: -0.995931088924408}\n",
      "{word: lesson, index: 15, tag: NOUN, rank_score: -0.0008581876754760742}\n",
      "{word: new, index: 21, tag: ADJ, rank_score: -0.0007919073104858398}\n",
      "{word: is, index: 19, tag: VERB, rank_score: -0.00026983022689819336}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: peek, index: 10, tag: NOUN, rank_score: -0.0011954307556152344}\n",
      "{word: portrait, index: 4, tag: NOUN, rank_score: -0.0005932450294494629}\n",
      "{word: than, index: 1, tag: ADP, rank_score: -0.0005562305450439453}\n",
      "{word: revolution, index: 15, tag: NOUN, rank_score: -0.00048214197158813477}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: charming, index: 21, tag: ADJ, rank_score: -0.011001765727996826}\n",
      "{word: cannes, index: 26, tag: NOUN, rank_score: -0.0019100308418273926}\n",
      "{word: is, index: 23, tag: VERB, rank_score: 0.0009661316871643066}\n",
      "{word: result, index: 22, tag: NOUN, rank_score: 0.0008884072303771973}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: pseudo-sophisticated, index: 9, tag: ADJ, rank_score: -0.04231739044189453}\n",
      "{word: patter, index: 7, tag: NOUN, rank_score: -0.0020614266395568848}\n",
      "{word: remainder, index: 14, tag: NOUN, rank_score: -0.0013203620910644531}\n",
      "{word: composed, index: 4, tag: VERB, rank_score: -0.0007742643356323242}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: for, index: 9, tag: ADP, rank_score: -0.00018870830535888672}\n",
      "{word: so, index: 1, tag: ADV, rank_score: -0.00010395050048828125}\n",
      "{word: movie, index: 4, tag: NOUN, rank_score: 9.953975677490234e-05}\n",
      "{word: much, index: 2, tag: ADV, rank_score: 9.721517562866211e-05}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: which, index: 9, tag: DET, rank_score: -0.00017839670181274414}\n",
      "{word: self-indulgent, index: 3, tag: ADJ, rank_score: -6.598234176635742e-05}\n",
      "{word: pompous, index: 13, tag: ADJ, rank_score: -4.565715789794922e-05}\n",
      "{word: incoherent, index: 2, tag: NOUN, rank_score: 3.7729740142822266e-05}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: pretentious, index: 27, tag: ADJ, rank_score: -0.00017529726028442383}\n",
      "{word: meaningless, index: 28, tag: NOUN, rank_score: -4.5239925384521484e-05}\n",
      "{word: of, index: 26, tag: ADP, rank_score: 3.218650817871094e-05}\n",
      "{word: prattle, index: 29, tag: NOUN, rank_score: -2.2172927856445312e-05}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: for, index: 26, tag: ADP, rank_score: -0.8686785101890564}\n",
      "{word: demands, index: 12, tag: NOUN, rank_score: -0.8393073678016663}\n",
      "{word: trading, index: 22, tag: NOUN, rank_score: -0.791023313999176}\n",
      "{word: labute, index: 14, tag: ADJ, rank_score: -0.6157995462417603}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: lost, index: 35, tag: VERB, rank_score: -0.9816185832023621}\n",
      "{word: thinks, index: 24, tag: VERB, rank_score: -0.0009434223175048828}\n",
      "{word: 've, index: 34, tag: VERB, rank_score: -0.000751495361328125}\n",
      "{word: 're, index: 19, tag: VERB, rank_score: -0.0007326006889343262}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: how, index: 12, tag: ADV, rank_score: -0.9708905816078186}\n",
      "{word: of, index: 10, tag: ADP, rank_score: -0.10083341598510742}\n",
      "{word: inspiring, index: 6, tag: VERB, rank_score: -0.008436143398284912}\n",
      "{word: ridiculous, index: 13, tag: ADJ, rank_score: 0.0015924572944641113}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: testament, index: 26, tag: NOUN, rank_score: 0.0007649064064025879}\n",
      "{word: it, index: 22, tag: PRON, rank_score: 0.0007538795471191406}\n",
      "{word: integrity, index: 29, tag: NOUN, rank_score: 0.0006980299949645996}\n",
      "{word: band, index: 34, tag: NOUN, rank_score: 0.00036323070526123047}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: reveals, index: 0, tag: NOUN, rank_score: -0.0002804398536682129}\n",
      "{word: how, index: 1, tag: ADV, rank_score: -0.0001379251480102539}\n",
      "{word: our, index: 3, tag: PRON, rank_score: 2.491474151611328e-05}\n",
      "{word: important, index: 2, tag: ADJ, rank_score: 2.4557113647460938e-05}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: whereas, index: 0, tag: ADP, rank_score: -0.7145054936408997}\n",
      "{word: sardonic, index: 15, tag: ADJ, rank_score: -0.6737275123596191}\n",
      "{word: for, index: 21, tag: ADP, rank_score: -0.46086573600769043}\n",
      "{word: caustic, index: 19, tag: ADJ, rank_score: -0.31865397095680237}\n",
      " \n",
      "['VERB', 'ADJ']\n",
      "{word: to, index: 47, tag: PRT, rank_score: -0.09373778104782104}\n",
      "{word: pleasant, index: 39, tag: ADJ, rank_score: -0.07891881465911865}\n",
      "{word: eat, index: 48, tag: VERB, rank_score: -0.04292958974838257}\n",
      "{word: is, index: 33, tag: VERB, rank_score: -0.02462780475616455}\n",
      " \n",
      ":: 11 sentences remaining.\n",
      "Predicting inputs...\n",
      ":: Sentence predictions done.\n"
     ]
    }
   ],
   "source": [
    "tg = PosNegTemplateGeneratorApp2(model, models)\n",
    "templates = tg.generate_templates(instances, n_masks=2, ranked_words_count=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaf7e38",
   "metadata": {},
   "source": [
    "#### Tempo de execução para 100 instâncias: 4m 10.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c3c1541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>template_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a well-made  thoughtful  well-acted clunker  but a clunker nonetheless .</td>\n",
       "      <td>a {mask} {mask} well-acted clunker but a clunker nonetheless .</td>\n",
       "      <td>a {pos_adj} {neg_adj} well-acted clunker but a clunker nonetheless .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>could the country bears really be as bad as its trailers ?</td>\n",
       "      <td>{mask} the country bears really be as {mask} as its trailers ?</td>\n",
       "      <td>{neg_verb} the country bears really be as {neg_adj} as its trailers ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>you'll probably love it .</td>\n",
       "      <td>you {mask} probably {mask} it .</td>\n",
       "      <td>you {pos_verb} probably {pos_verb} it .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>and the lesson  in the end  is nothing new .</td>\n",
       "      <td>and the lesson in the end {mask} nothing {mask} .</td>\n",
       "      <td>and the lesson in the end {pos_verb} nothing {neg_adj} .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>the charming result is festival in cannes .</td>\n",
       "      <td>the {mask} result {mask} festival in cannes .</td>\n",
       "      <td>the {pos_adj} result {pos_verb} festival in cannes .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>half of it is composed of snappy patter and pseudo-sophisticated cultural observations  while the remainder .</td>\n",
       "      <td>half of it is {mask} of snappy patter and {mask} cultural observations while the remainder .</td>\n",
       "      <td>half of it is {neg_verb} of snappy patter and {neg_adj} cultural observations while the remainder .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>a dreary  incoherent  self-indulgent mess of a movie in which a bunch of pompous windbags drone on inanely for two hours .</td>\n",
       "      <td>a dreary incoherent {mask} mess of a movie in which a bunch of {mask} windbags drone on inanely for two hours .</td>\n",
       "      <td>a dreary incoherent {neg_adj} mess of a movie in which a bunch of {neg_adj} windbags drone on inanely for two hours .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>/ but daphne  you're too buff / fred thinks he's tough / and velma - wow  you've lost weight !</td>\n",
       "      <td>/ but daphne you 're too buff / fred {mask} he 's tough / and velma - wow you 've {mask} weight !</td>\n",
       "      <td>/ but daphne you 're too buff / fred {neg_verb} he 's tough / and velma - wow you 've {neg_verb} weight !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>is inspiring ironic and revelatory of just how ridiculous and money-oriented the record industry really is .</td>\n",
       "      <td>is {mask} ironic and revelatory of just how {mask} and money-oriented the record industry really is .</td>\n",
       "      <td>is {pos_verb} ironic and revelatory of just how {neg_adj} and money-oriented the record industry really is .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>whereas the extremely competent hitman films such as pulp fiction and get shorty resonate a sardonic verve to their caustic purpose for existing  who is cletis tout ?</td>\n",
       "      <td>whereas the extremely competent hitman films such as pulp fiction and get shorty resonate a {mask} verve to their {mask} purpose for existing who is cletis tout ?</td>\n",
       "      <td>whereas the extremely competent hitman films such as pulp fiction and get shorty resonate a {neg_adj} verve to their {neg_adj} purpose for existing who is cletis tout ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>this is a movie that is what it is : a pleasant distraction a friday night diversion an excuse to eat popcorn .</td>\n",
       "      <td>this is a movie that is what it is : a {mask} distraction a friday night diversion an excuse to {mask} popcorn .</td>\n",
       "      <td>this is a movie that is what it is : a {pos_adj} distraction a friday night diversion an excuse to {pos_verb} popcorn .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  \\\n",
       "0       0   \n",
       "1       0   \n",
       "2       1   \n",
       "3       0   \n",
       "4       1   \n",
       "5       0   \n",
       "6       0   \n",
       "7       0   \n",
       "8       1   \n",
       "9       1   \n",
       "10      1   \n",
       "\n",
       "                                                                                                                                                             original_text  \\\n",
       "0                                                                                                 a well-made  thoughtful  well-acted clunker  but a clunker nonetheless .   \n",
       "1                                                                                                               could the country bears really be as bad as its trailers ?   \n",
       "2                                                                                                                                                you'll probably love it .   \n",
       "3                                                                                                                             and the lesson  in the end  is nothing new .   \n",
       "4                                                                                                                              the charming result is festival in cannes .   \n",
       "5                                                            half of it is composed of snappy patter and pseudo-sophisticated cultural observations  while the remainder .   \n",
       "6                                               a dreary  incoherent  self-indulgent mess of a movie in which a bunch of pompous windbags drone on inanely for two hours .   \n",
       "7                                                                           / but daphne  you're too buff / fred thinks he's tough / and velma - wow  you've lost weight !   \n",
       "8                                                             is inspiring ironic and revelatory of just how ridiculous and money-oriented the record industry really is .   \n",
       "9   whereas the extremely competent hitman films such as pulp fiction and get shorty resonate a sardonic verve to their caustic purpose for existing  who is cletis tout ?   \n",
       "10                                                         this is a movie that is what it is : a pleasant distraction a friday night diversion an excuse to eat popcorn .   \n",
       "\n",
       "                                                                                                                                                           masked_text  \\\n",
       "0                                                                                                       a {mask} {mask} well-acted clunker but a clunker nonetheless .   \n",
       "1                                                                                                       {mask} the country bears really be as {mask} as its trailers ?   \n",
       "2                                                                                                                                      you {mask} probably {mask} it .   \n",
       "3                                                                                                                    and the lesson in the end {mask} nothing {mask} .   \n",
       "4                                                                                                                        the {mask} result {mask} festival in cannes .   \n",
       "5                                                                         half of it is {mask} of snappy patter and {mask} cultural observations while the remainder .   \n",
       "6                                                      a dreary incoherent {mask} mess of a movie in which a bunch of {mask} windbags drone on inanely for two hours .   \n",
       "7                                                                    / but daphne you 're too buff / fred {mask} he 's tough / and velma - wow you 've {mask} weight !   \n",
       "8                                                                is {mask} ironic and revelatory of just how {mask} and money-oriented the record industry really is .   \n",
       "9   whereas the extremely competent hitman films such as pulp fiction and get shorty resonate a {mask} verve to their {mask} purpose for existing who is cletis tout ?   \n",
       "10                                                    this is a movie that is what it is : a {mask} distraction a friday night diversion an excuse to {mask} popcorn .   \n",
       "\n",
       "                                                                                                                                                               template_text  \n",
       "0                                                                                                       a {pos_adj} {neg_adj} well-acted clunker but a clunker nonetheless .  \n",
       "1                                                                                                      {neg_verb} the country bears really be as {neg_adj} as its trailers ?  \n",
       "2                                                                                                                                    you {pos_verb} probably {pos_verb} it .  \n",
       "3                                                                                                                   and the lesson in the end {pos_verb} nothing {neg_adj} .  \n",
       "4                                                                                                                       the {pos_adj} result {pos_verb} festival in cannes .  \n",
       "5                                                                        half of it is {neg_verb} of snappy patter and {neg_adj} cultural observations while the remainder .  \n",
       "6                                                      a dreary incoherent {neg_adj} mess of a movie in which a bunch of {neg_adj} windbags drone on inanely for two hours .  \n",
       "7                                                                  / but daphne you 're too buff / fred {neg_verb} he 's tough / and velma - wow you 've {neg_verb} weight !  \n",
       "8                                                               is {pos_verb} ironic and revelatory of just how {neg_adj} and money-oriented the record industry really is .  \n",
       "9   whereas the extremely competent hitman films such as pulp fiction and get shorty resonate a {neg_adj} verve to their {neg_adj} purpose for existing who is cletis tout ?  \n",
       "10                                                   this is a movie that is what it is : a {pos_adj} distraction a friday night diversion an excuse to {pos_verb} popcorn .  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tg.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0571a42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_verb': ['is', 'eat', 'love', 'inspiring', \"'ll\"],\n",
       " 'neg_verb': ['composed', 'lost', 'thinks', 'could'],\n",
       " 'pos_adj': ['pleasant', 'charming', 'well-made'],\n",
       " 'neg_adj': ['thoughtful',\n",
       "  'self-indulgent',\n",
       "  'pseudo-sophisticated',\n",
       "  'sardonic',\n",
       "  'caustic',\n",
       "  'new',\n",
       "  'ridiculous',\n",
       "  'pompous',\n",
       "  'bad']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6be4e9",
   "metadata": {},
   "source": [
    "## Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad2b0738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.test_types import MFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d3415da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicons = tg.lexicons\n",
    "templates = tg.template_texts\n",
    "masked = tg.masked_texts\n",
    "labels = [sent.prediction.label for sent in tg.sentences]\n",
    "\n",
    "editor = Editor()\n",
    "editor.add_lexicon('pos_verb', lexicons['pos_verb'])\n",
    "editor.add_lexicon('neg_verb', lexicons['neg_verb'])\n",
    "editor.add_lexicon('pos_adj', lexicons['pos_adj'])\n",
    "editor.add_lexicon('neg_adj', lexicons['neg_adj'])\n",
    "\n",
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c134553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for template, label, i in zip(templates, labels, range(len(templates))):\n",
    "    t = editor.template(template, remove_duplicates=True, labels=int(label))\n",
    "\n",
    "    suite.add(MFT(\n",
    "        data=t.data,\n",
    "        labels=label,\n",
    "        capability=\"Vocabullary\", \n",
    "        name=f\"Test: MFT with vocabullary - template{i+1}\",\n",
    "        description=\"Checking if the model can handle vocabullary\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2a19cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: MFT with vocabullary - template1\n",
      "Predicting 27 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-263ca9d23a33>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: MFT with vocabullary - template2\n",
      "Predicting 36 examples\n",
      "Running Test: MFT with vocabullary - template3\n",
      "Predicting 5 examples\n",
      "Running Test: MFT with vocabullary - template4\n",
      "Predicting 45 examples\n",
      "Running Test: MFT with vocabullary - template5\n",
      "Predicting 15 examples\n",
      "Running Test: MFT with vocabullary - template6\n",
      "Predicting 36 examples\n",
      "Running Test: MFT with vocabullary - template7\n",
      "Predicting 9 examples\n",
      "Running Test: MFT with vocabullary - template8\n",
      "Predicting 4 examples\n",
      "Running Test: MFT with vocabullary - template9\n",
      "Predicting 45 examples\n",
      "Running Test: MFT with vocabullary - template10\n",
      "Predicting 9 examples\n",
      "Running Test: MFT with vocabullary - template11\n",
      "Predicting 15 examples\n"
     ]
    }
   ],
   "source": [
    "suite.run(model.predict, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88a9ce8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabullary\n",
      "\n",
      "Test: MFT with vocabullary - template1\n",
      "Test cases:      27\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Test: MFT with vocabullary - template2\n",
      "Test cases:      36\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Test: MFT with vocabullary - template3\n",
      "Test cases:      5\n",
      "Fails (rate):    2 (40.0%)\n",
      "\n",
      "Example fails:\n",
      "0.0 you 'll probably 'll it .\n",
      "----\n",
      "0.1 you eat probably eat it .\n",
      "----\n",
      "\n",
      "\n",
      "Test: MFT with vocabullary - template4\n",
      "Test cases:      45\n",
      "Fails (rate):    3 (6.7%)\n",
      "\n",
      "Example fails:\n",
      "0.6 and the lesson in the end inspiring nothing sardonic .\n",
      "----\n",
      "0.5 and the lesson in the end is nothing sardonic .\n",
      "----\n",
      "0.7 and the lesson in the end inspiring nothing bad .\n",
      "----\n",
      "\n",
      "\n",
      "Test: MFT with vocabullary - template5\n",
      "Test cases:      15\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Test: MFT with vocabullary - template6\n",
      "Test cases:      36\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Test: MFT with vocabullary - template7\n",
      "Test cases:      9\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Test: MFT with vocabullary - template8\n",
      "Test cases:      4\n",
      "Fails (rate):    3 (75.0%)\n",
      "\n",
      "Example fails:\n",
      "1.0 / but daphne you 're too buff / fred composed he 's tough / and velma - wow you 've composed weight !\n",
      "----\n",
      "1.0 / but daphne you 're too buff / fred could he 's tough / and velma - wow you 've could weight !\n",
      "----\n",
      "0.9 / but daphne you 're too buff / fred thinks he 's tough / and velma - wow you 've thinks weight !\n",
      "----\n",
      "\n",
      "\n",
      "Test: MFT with vocabullary - template9\n",
      "Test cases:      45\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Test: MFT with vocabullary - template10\n",
      "Test cases:      9\n",
      "Fails (rate):    4 (44.4%)\n",
      "\n",
      "Example fails:\n",
      "0.0 whereas the extremely competent hitman films such as pulp fiction and get shorty resonate a bad verve to their bad purpose for existing who is cletis tout ?\n",
      "----\n",
      "0.1 whereas the extremely competent hitman films such as pulp fiction and get shorty resonate a pseudo-sophisticated verve to their pseudo-sophisticated purpose for existing who is cletis tout ?\n",
      "----\n",
      "0.0 whereas the extremely competent hitman films such as pulp fiction and get shorty resonate a ridiculous verve to their ridiculous purpose for existing who is cletis tout ?\n",
      "----\n",
      "\n",
      "\n",
      "Test: MFT with vocabullary - template11\n",
      "Test cases:      15\n",
      "Fails (rate):    3 (20.0%)\n",
      "\n",
      "Example fails:\n",
      "0.2 this is a movie that is what it is : a well-made distraction a friday night diversion an excuse to 'll popcorn .\n",
      "----\n",
      "0.3 this is a movie that is what it is : a well-made distraction a friday night diversion an excuse to is popcorn .\n",
      "----\n",
      "0.5 this is a movie that is what it is : a well-made distraction a friday night diversion an excuse to inspiring popcorn .\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1b259bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.save('./suites/posneg-approach2.suite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33065add",
   "metadata": {},
   "source": [
    "# Carregando suite de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "563d7be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed5b5af5b4f4aab8747c3e46bfa5466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'Test: MFT with vocab…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from checklist.test_suite import TestSuite\n",
    "suite = TestSuite.from_file('./suites/posneg-approach2.suite')\n",
    "\n",
    "suite.visual_summary_table()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d158b0884c902cbe5122803144f593e89d3599d27de4904257d93ccf35897e83"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
