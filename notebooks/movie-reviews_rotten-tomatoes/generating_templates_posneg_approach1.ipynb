{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e2c728",
   "metadata": {},
   "source": [
    "# Abordagem 1\n",
    "\n",
    "Usando a abordagem 1 para gerar templates com foco em templates positivos e negativos. Uma possível aplicação seria testar a capacidade linguística \"Vocabulary\" com o teste MFT.\n",
    "\n",
    "As etapas desta abordagem são:\n",
    "\n",
    "1. Rankear as palavras das instâncias completas\n",
    "2. Quebrar as instâncias em sentenças\n",
    "3. Filtrar as sentenças que contêm ao menos uma das palavras mais bem rankeadas na etapa anterior\n",
    "4. Filtrar as sentenças com palavras relevantes (substantivos, adjetivos e verbos)\n",
    "5. Substituir as palavras relevantes por máscaras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897c3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da847fc",
   "metadata": {},
   "source": [
    "## Carregando o dataset, o modelo alvo e os modelos auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e018fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>allen's underestimated charm delivers more goodies than lumps of coal .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>skip the film and buy the philip glass soundtrack cd .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>involving at times  but lapses quite casually into the absurd .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>while hoffman's performance is great  the subject matter goes nowhere .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>a flick about our infantilized culture that isn't entirely infantile .</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      1   \n",
       "1      0   \n",
       "2      0   \n",
       "3      0   \n",
       "4      1   \n",
       "\n",
       "                                                                       text  \\\n",
       "0  allen's underestimated charm delivers more goodies than lumps of coal .    \n",
       "1                   skip the film and buy the philip glass soundtrack cd .    \n",
       "2          involving at times  but lapses quite casually into the absurd .    \n",
       "3  while hoffman's performance is great  the subject matter goes nowhere .    \n",
       "4   a flick about our infantilized culture that isn't entirely infantile .    \n",
       "\n",
       "   words  \n",
       "0     11  \n",
       "1     11  \n",
       "2     11  \n",
       "3     11  \n",
       "4     11  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "movie_reviews_rt_df = pd.read_csv('./data/data-rt-100samples.csv')\n",
    "movie_reviews_rt_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264d0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "def pre_proccess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[\"\\',!-.:-@0-9/]()', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Wrapper to adapt output format\n",
    "class SentimentAnalisysModelWrapper:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __predict(self, text_input):\n",
    "        text_preprocessed = pre_proccess(text_input)\n",
    "        tokenized = self.tokenizer(text_preprocessed, padding=True, truncation=True, max_length=512, \n",
    "                                    add_special_tokens = True, return_tensors=\"pt\")\n",
    "        \n",
    "        tensor_logits = self.model(**tokenized)\n",
    "        prob = softmax(tensor_logits[0]).detach().numpy()\n",
    "        pred = np.argmax(prob)\n",
    "        \n",
    "        return pred, prob\n",
    "    \n",
    "    def predict_label(self, text_inputs):\n",
    "        return self.predict(text_inputs)[0]\n",
    "        \n",
    "    def predict_proba(self, text_inputs):\n",
    "        return self.predict(text_inputs)[1]\n",
    "        \n",
    "    def predict(self, text_inputs):\n",
    "        if isinstance(text_inputs, str):\n",
    "            text_inputs = [text_inputs]\n",
    "        \n",
    "        preds = []\n",
    "        probs = []\n",
    "\n",
    "        for text_input in text_inputs:\n",
    "            pred, prob = self.__predict(text_input)\n",
    "            preds.append(pred)\n",
    "            probs.append(prob[0])\n",
    "\n",
    "        return np.array(preds), np.array(probs) # ([0, 1], [[0.99, 0.01], [0.03, 0.97]])\n",
    "\n",
    "# Auxiliar function to load and wrap a model from Hugging Face\n",
    "def load_model(model_name):\n",
    "    print(f'Loading model {model_name}...')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    return SentimentAnalisysModelWrapper(model, tokenizer)\n",
    "\n",
    "# Hugging Face hosted model names \n",
    "movie_reviews_models = {\n",
    "    'bert': 'textattack/bert-base-uncased-rotten-tomatoes', \n",
    "    'albert': 'textattack/albert-base-v2-rotten-tomatoes', \n",
    "    'distilbert': 'textattack/distilbert-base-uncased-rotten-tomatoes', \n",
    "    'roberta': 'textattack/roberta-base-rotten-tomatoes', \n",
    "    'xlnet': 'textattack/xlnet-base-cased-rotten-tomatoes'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f271eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model textattack/albert-base-v2-rotten-tomatoes...\n",
      "Loading model textattack/distilbert-base-uncased-rotten-tomatoes...\n",
      "Loading model textattack/roberta-base-rotten-tomatoes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-rotten-tomatoes were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model textattack/xlnet-base-cased-rotten-tomatoes...\n",
      "Loading model textattack/bert-base-uncased-rotten-tomatoes...\n"
     ]
    }
   ],
   "source": [
    "m1 = load_model(movie_reviews_models['albert'])\n",
    "m2 = load_model(movie_reviews_models['distilbert'])\n",
    "m3 = load_model(movie_reviews_models['roberta'])\n",
    "m4 = load_model(movie_reviews_models['xlnet'])\n",
    "\n",
    "# Models to be used as oracle\n",
    "models = [m1, m2, m3, m4]\n",
    "# Target model\n",
    "model = load_model(movie_reviews_models['bert'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae89b5",
   "metadata": {},
   "source": [
    "# Gerando os templates\n",
    "O método de rankeamento das palavras usado no PosNegTemplateGenerator é o Replace-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60dc1af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_generator.tasks.sentiment_analisys import PosNegTemplateGeneratorApp1\n",
    "\n",
    "tg = PosNegTemplateGeneratorApp1(model, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f595e69",
   "metadata": {},
   "source": [
    "### Número inicial de instâncias: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6261506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling instances\n",
    "np.random.seed(220)\n",
    "n_instances = 5\n",
    "df_sampled = movie_reviews_rt_df.sample(n_instances)\n",
    "\n",
    "instances = [x for x in df_sampled['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "660add17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking words using Replace-1 Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-263ca9d23a33>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting texts to sentences...\n",
      ":: 6 sentences were generated.\n",
      "Filtering instances by contaning ranked words...\n",
      ":: 1 sentences remaining.\n",
      "Filtering instances by relevant words...\n",
      ":: 0 sentences remaining.\n"
     ]
    }
   ],
   "source": [
    "templates = tg.generate_templates(instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d150cb",
   "metadata": {},
   "source": [
    "#### Tempo de execução para 5 instâncias: 13.3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "193f1b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>template_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, original_text, masked_text, template_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tg.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f98d8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_verb': [], 'neg_verb': [], 'pos_adj': [], 'neg_adj': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a27f1f",
   "metadata": {},
   "source": [
    "### Número inicial de instâncias: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd4a7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using all 100 instances\n",
    "instances = [x for x in movie_reviews_rt_df['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1f3f383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking words using Replace-1 Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-263ca9d23a33>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = softmax(tensor_logits[0]).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting texts to sentences...\n",
      ":: 134 sentences were generated.\n",
      "Filtering instances by contaning ranked words...\n",
      ":: 23 sentences remaining.\n",
      "Filtering instances by relevant words...\n",
      ":: 0 sentences remaining.\n"
     ]
    }
   ],
   "source": [
    "templates = tg.generate_templates(instances, n_masks=2, range_words=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaf7e38",
   "metadata": {},
   "source": [
    "#### Tempo de execução para 100 instâncias: 5m 16.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c3c1541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original_text</th>\n",
       "      <th>masked_text</th>\n",
       "      <th>template_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, original_text, masked_text, template_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tg.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0571a42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_verb': [], 'neg_verb': [], 'pos_adj': [], 'neg_adj': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b128e49",
   "metadata": {},
   "source": [
    "## Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad2b0738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.test_types import MFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d3415da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicons = tg.lexicons\n",
    "templates = tg.template_texts\n",
    "labels = [sent.prediction.label for sent in tg.sentences]\n",
    "\n",
    "editor = Editor()\n",
    "editor.add_lexicon('pos_verb', lexicons['pos_verb'])\n",
    "editor.add_lexicon('neg_verb', lexicons['neg_verb'])\n",
    "editor.add_lexicon('pos_adj', lexicons['pos_adj'])\n",
    "editor.add_lexicon('neg_adj', lexicons['neg_adj'])\n",
    "\n",
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c134553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "lbl = []\n",
    "for template, label in zip(templates, labels):\n",
    "    t = editor.template(template, remove_duplicates=True, labels=int(label))\n",
    "    data.extend(t.data)\n",
    "    lbl.extend(t.labels)\n",
    "\n",
    "suite.add(MFT(\n",
    "    data=data,\n",
    "    labels=lbl,\n",
    "    capability=\"Vocabullary\",\n",
    "    name=\"Template Generator - Vocabulary in MFT\",\n",
    "    description=\"Checking if the model can handle vocabulary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2a19cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Template Generator - Vocabulary in MFT\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-941c7101b451>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msuite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\TCC-Adson\\lib\\site-packages\\checklist\\test_suite.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, predict_and_confidence_fn, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Running'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m             \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_and_confidence_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapabilities\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TCC-Adson\\lib\\site-packages\\checklist\\abstract_test.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, predict_and_confidence_fn, overwrite, verbose, n, seed)\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;31m# Checking just to avoid predicting in vain, will be created in run_from_preds_confs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_create_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[0mexamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_indexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexample_list_and_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TCC-Adson\\lib\\site-packages\\checklist\\abstract_test.py\u001b[0m in \u001b[0;36mexample_list_and_indices\u001b[1;34m(self, n, seed)\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[0midxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_idxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midxs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m             \u001b[0mall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midxs\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mresult_indexes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "suite.run(model.predict, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d158b0884c902cbe5122803144f593e89d3599d27de4904257d93ccf35897e83"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('TCC-Adson': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
